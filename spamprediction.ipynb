{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split #function for training and testing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer #text to numerical data\n",
    "from sklearn.linear_model import LogisticRegression #the algorithm that we use\n",
    "from sklearn.metrics import accuracy_score #to evaluate our model\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to load data\n",
    "raw_mail_data = pd.read_csv(\"D:\\workspace python\\mlprojects\\spam prediction project\\mail_data.csv\")\n",
    "raw_mail_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take care of null values with null strings\n",
    "mail_data = raw_mail_data.where(pd.notnull(raw_mail_data),\"\")\n",
    "mail_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking dimensions\n",
    "mail_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding -> ham - 1 | spam - 0\n",
    "#replace all spam category values with 0\n",
    "mail_data.loc[mail_data[\"Category\"]=='spam',\"Category\",] = 0\n",
    "\n",
    "#replace all ham category values with 0\n",
    "mail_data.loc[mail_data[\"Category\"]=='ham',\"Category\",] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperating the data as texts and labels\n",
    "x = mail_data['Message']\n",
    "y = mail_data['Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572,)\n",
      "(4457,)\n",
      "(1115,)\n"
     ]
    }
   ],
   "source": [
    "#spliting x and y to training and testing data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=3)\n",
    "#random state=3 splits data in the same manner\n",
    "print(x.shape)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 5413)\t0.6198254967574347\n",
      "  (0, 4456)\t0.4168658090846482\n",
      "  (0, 2224)\t0.413103377943378\n",
      "  (0, 3811)\t0.34780165336891333\n",
      "  (0, 2329)\t0.38783870336935383\n",
      "  (1, 4080)\t0.18880584110891163\n",
      "  (1, 3185)\t0.29694482957694585\n",
      "  (1, 3325)\t0.31610586766078863\n",
      "  (1, 2957)\t0.3398297002864083\n",
      "  (1, 2746)\t0.3398297002864083\n",
      "  (1, 918)\t0.22871581159877646\n",
      "  (1, 1839)\t0.2784903590561455\n",
      "  (1, 2758)\t0.3226407885943799\n",
      "  (1, 2956)\t0.33036995955537024\n",
      "  (1, 1991)\t0.33036995955537024\n",
      "  (1, 3046)\t0.2503712792613518\n",
      "  (1, 3811)\t0.17419952275504033\n",
      "  (2, 407)\t0.509272536051008\n",
      "  (2, 3156)\t0.4107239318312698\n",
      "  (2, 2404)\t0.45287711070606745\n",
      "  (2, 6601)\t0.6056811524587518\n",
      "  (3, 2870)\t0.5864269879324768\n",
      "  (3, 7414)\t0.8100020912469564\n",
      "  (4, 50)\t0.23633754072626942\n",
      "  (4, 5497)\t0.15743785051118356\n",
      "  :\t:\n",
      "  (4454, 4602)\t0.2669765732445391\n",
      "  (4454, 3142)\t0.32014451677763156\n",
      "  (4455, 2247)\t0.37052851863170466\n",
      "  (4455, 2469)\t0.35441545511837946\n",
      "  (4455, 5646)\t0.33545678464631296\n",
      "  (4455, 6810)\t0.29731757715898277\n",
      "  (4455, 6091)\t0.23103841516927642\n",
      "  (4455, 7113)\t0.30536590342067704\n",
      "  (4455, 3872)\t0.3108911491788658\n",
      "  (4455, 4715)\t0.30714144758811196\n",
      "  (4455, 6916)\t0.19636985317119715\n",
      "  (4455, 3922)\t0.31287563163368587\n",
      "  (4455, 4456)\t0.24920025316220423\n",
      "  (4456, 141)\t0.292943737785358\n",
      "  (4456, 647)\t0.30133182431707617\n",
      "  (4456, 6311)\t0.30133182431707617\n",
      "  (4456, 5569)\t0.4619395404299172\n",
      "  (4456, 6028)\t0.21034888000987115\n",
      "  (4456, 7154)\t0.24083218452280053\n",
      "  (4456, 7150)\t0.3677554681447669\n",
      "  (4456, 6249)\t0.17573831794959716\n",
      "  (4456, 6307)\t0.2752760476857975\n",
      "  (4456, 334)\t0.2220077711654938\n",
      "  (4456, 5778)\t0.16243064490100795\n",
      "  (4456, 2870)\t0.31523196273113385\n"
     ]
    }
   ],
   "source": [
    "# transform the text data to feature vectors that can be used as input to the Logistic regression\n",
    "\n",
    "feature_extraction = TfidfVectorizer(min_df = 1, stop_words='english', lowercase='True')\n",
    "with open(\"feature_extraction_SM\",\"wb\") as f:\n",
    "    pickle.dump(TfidfVectorizer(min_df = 1, stop_words='english', lowercase='True'),f)\n",
    "with open(\"feature_extraction_SM\",\"rb\") as f:\n",
    "    fe = pickle.load(f)\n",
    "\n",
    "x_train_features = feature_extraction.fit_transform(x_train) #fit and transform to features\n",
    "x_test_features = feature_extraction.transform(x_test) #we dont fit data again for test data\n",
    "\n",
    "# convert y train and test as integers \n",
    "y_train = y_train.astype('int')\n",
    "y_test = y_test.astype('int')\n",
    "print(x_train_features) #which is scored into numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train logistic reg model\n",
    "#x data represented into numerical form \n",
    "model = LogisticRegression()\n",
    "model.fit(x_train_features,y_train) #both in numerical form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9670181736594121"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluating the model\n",
    "#predict on training data\n",
    "\n",
    "predict_training_data = model.predict(x_train_features);\n",
    "accuracy = accuracy_score(y_train,predict_training_data)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9659192825112107"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prediction on test data\n",
    "predict_training_data = model.predict(x_test_features);\n",
    "accuracy = accuracy_score(y_test,predict_training_data)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAM\n"
     ]
    }
   ],
   "source": [
    "mail = [\"TODAY is Sorry day.! If ever i was angry with you, if ever i misbehaved or hurt you? plz plz JUST SLAP URSELF Bcoz, Its ur fault, I'm basically GOOD\"]\n",
    "#text to feature vectors\n",
    "mail = feature_extraction.transform(mail)\n",
    "\n",
    "if (model.predict(mail)==1):\n",
    "    print(\"HAM\")\n",
    "else:\n",
    "    print(\"SPAM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPAM\n"
     ]
    }
   ],
   "source": [
    "mail = [\"Here is your discount code RP176781. To stop further messages reply stop. www.regalportfolio.co.uk. Customer Services 08717205546\"]\n",
    "#text to feature vectors\n",
    "mail = feature_extraction.transform(mail)\n",
    "if (model.predict(mail)==1):\n",
    "    print(\"HAM\")\n",
    "else:\n",
    "    print(\"SPAM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle\n",
    "with open(\"spam_mail_prediction_model\",\"wb\") as f:\n",
    "    pickle.dump(model,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"spam_mail_prediction_model\",\"rb\") as f:\n",
    "    mp = pickle.load(f)\n",
    "mp.predict(mail)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a54084e6b208ee8d1ce3989ffc20924477a5f55f5a43e22e699a6741623861e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
